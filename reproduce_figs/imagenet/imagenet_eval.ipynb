{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, time, os, random\n",
    "from os.path import join as oj\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "\n",
    "import visualize as viz\n",
    "import tiling\n",
    "import agglomerate\n",
    "import operator\n",
    "import pickle\n",
    "from cd import cd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import imagenet.imagenet as dset\n",
    "import scores as score_funcs\n",
    "\n",
    "from agglomerate import get_scores\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import models\n",
    "\n",
    "# get model\n",
    "# model = models.alexnet(pretrained=True).cuda().eval()\n",
    "model = models.vgg16(pretrained=True).cuda().eval()\n",
    "model_type='vgg' # alexnet, vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'cd'\n",
    "sweep_dim = 14\n",
    "layer = 'softmax'\n",
    "use_abs = False\n",
    "num_iters = 8\n",
    "percentile_include = 96\n",
    "batch = False\n",
    "_, val_loader = dset.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find best, worst examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "print(len(val_loader))\n",
    "for i, im in enumerate(val_loader):\n",
    "    im_torch, label = Variable(im[0].cuda()), im[1].numpy()[0]\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    pred = model(im_torch).data[0, label]\n",
    "    preds.append(pred)\n",
    "pickle.dump(preds, open('preds_imagenet.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top idxs [30246 30209 27731 21483  1472 30217 30247 30596 20897  7065]\n",
      "bot idxs [46516 48180 15466 34520 45305 23247 19298 28353 12554  8366]\n"
     ]
    }
   ],
   "source": [
    "preds = pickle.load(open('preds_imagenet.pkl', 'rb'))\n",
    "top_idxs = np.argsort(preds)[::-1]\n",
    "preds[top_idxs[0]]\n",
    "top_10 = top_idxs[:10]\n",
    "bot_10 = top_idxs[-10:][::-1]\n",
    "print('top idxs', top_10)\n",
    "print('bot idxs', bot_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bad model\n",
    "np.random.seed(17042018)\n",
    "modify_prop = 0.008\n",
    "bad_model = copy.deepcopy(model).eval()\n",
    "for param in bad_model.parameters():\n",
    "    num_params = np.prod(list(param.data.size()))\n",
    "    num_modify = modify_prop * num_params\n",
    "    to_modify = np.random.choice([True, False], tuple(param.data.size()), \n",
    "                                 p=(modify_prop, 1-modify_prop))\n",
    "    cpu_param = param.data.cpu().numpy()\n",
    "    #permuted_vars = cpu_param[to_modify]\n",
    "    cpu_param[to_modify] = np.random.permutation(cpu_param[to_modify])\n",
    "    param.data = torch.cuda.FloatTensor(cpu_param) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    }
   ],
   "source": [
    "good_exs = [0] #4195, 22182, 35727, 1939, 4020, 6910]\n",
    "bad_exs = [] #[7224, 28123, 48736]\n",
    "all_data = {}\n",
    "for i, im in enumerate(val_loader):\n",
    "    if i % 100 == 0:\n",
    "        print(i, end=' ')\n",
    "    if i in good_exs or i in bad_exs:\n",
    "        all_data[i] = im\n",
    "    if i > max(good_exs):\n",
    "        break\n",
    "    \n",
    "\n",
    "#all_data = {i:im for i, im in enumerate(val_loader) if i in ex_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, im):\n",
    "    pred = model(im)\n",
    "    _, pred = pred[0].max(0)\n",
    "    return pred.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "Accuracy of bad model:  0.32374\n",
      "Accuracy of good model:  0.42778\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy of good, bad model\n",
    "num_correct, num_good_correct, num_total = 0, 0, 0\n",
    "\n",
    "for i, im in enumerate(val_loader):\n",
    "    im_torch, im_orig, label = Variable(im[0].cuda()), im[0].numpy().squeeze(), im[1].numpy()[0]\n",
    "    pred = bad_model(im_torch)\n",
    "    _, pred = pred[0].max(0)\n",
    "    pred = pred.data[0]\n",
    "    if pred == label:\n",
    "        num_correct += 1\n",
    "        \n",
    "    pred = model(im_torch)\n",
    "    _, pred = pred[0].max(0)\n",
    "    pred = pred.data[0]\n",
    "    if pred == label:\n",
    "        num_good_correct += 1\n",
    "        \n",
    "    num_total += 1\n",
    "    if num_total % 1000 == 0:\n",
    "        print(num_total)\n",
    "    #if num_total > 10000:\n",
    "        #break\n",
    "\n",
    "print(\"Accuracy of bad model: \", num_correct / num_total)\n",
    "print(\"Accuracy of good model: \", num_good_correct / num_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/linux/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07658673077821732"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(bad_model(im_torch)).data[0][good_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/linux/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/linux/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n",
      "/usr/local/linux/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/usr/local/linux/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "2000 0 0\n",
      "4000 0 0\n",
      "6000 0 0\n",
      "8000 0 0\n",
      "10000 0 0\n",
      "12000 0 0\n",
      "14000 0 0\n",
      "16000 0 0\n",
      "18000 0 0\n",
      "20000 0 0\n",
      "22000 0 0\n",
      "24000 0 0\n",
      "26000 0 0\n",
      "28000 0 0\n",
      "30000 0 0\n",
      "32000 0 0\n",
      "34000 0 0\n",
      "36000 0 0\n",
      "38000 0 0\n",
      "40000 0 0\n",
      "42000 0 0\n",
      "44000 0 0\n",
      "46000 0 0\n",
      "48000 0 0\n"
     ]
    }
   ],
   "source": [
    "good_int_sum = [[] for i in range(len(val_loader))]\n",
    "bad_int_sum = [[] for i in range(len(val_loader))]\n",
    "good_int_sums = [[] for i in range(len(val_loader))]\n",
    "bad_int_sums = [[] for i in range(len(val_loader))]\n",
    "decomp_cnt = 0\n",
    "ex_list = set([])\n",
    "good_correct = {}\n",
    "bad_correct = {}\n",
    "for i, im in enumerate(val_loader):\n",
    "    im_torch, im_orig, lab_num = Variable(im[0].cuda()), im[0].numpy().squeeze(), im[1].numpy()[0]\n",
    "    good_max, good_pred = F.softmax(model(im_torch)).max(1)\n",
    "    good_pred = good_pred.data[0]; good_max = good_max.data[0]\n",
    "    bad_max, bad_pred = F.softmax(bad_model(im_torch)).max(1)\n",
    "    bad_pred = bad_pred.data[0]; bad_max = bad_max.data[0]\n",
    "    \n",
    "    if (good_pred == lab_num or bad_pred == lab_num) and good_pred != bad_pred:\n",
    "        if good_pred == lab_num:\n",
    "            good_correct[i] = good_max - F.softmax(bad_model(im_torch)).data[0, good_pred]\n",
    "        else:\n",
    "            bad_correct[i] = bad_max - F.softmax(model(im_torch)).data[0, bad_pred]\n",
    "            \n",
    "    if False and good_pred != bad_pred and (good_pred == lab_num or bad_pred == lab_num) and good_max > 0.5 and bad_max > 0.5:\n",
    "        ex_list |= set([i])\n",
    "        \n",
    "        if False:\n",
    "            #lab_pred = np.argmax(dset.pred_ims(model, np.copy(im_orig)))\n",
    "\n",
    "            lists = agglomerate.agglomerate(model, dset.pred_ims, percentile_include, \n",
    "                                            method, sweep_dim, layer, im_orig, \n",
    "                                            good_pred, use_abs, num_iters=num_iters, \n",
    "                                            im_torch=im_torch, batch=False, model_type='vgg')\n",
    "            int_sum, int_sums = agglomerate.sum_interactions(lists)\n",
    "            good_int_sum[i] = int_sum\n",
    "            good_int_sums[i] = int_sums\n",
    "            lists = agglomerate.agglomerate(bad_model, dset.pred_ims, percentile_include, \n",
    "                                            method, sweep_dim, layer, im_orig, \n",
    "                                            bad_pred, use_abs, num_iters=num_iters, \n",
    "                                            im_torch=im_torch, model_type='vgg')\n",
    "            int_sum, int_sums = agglomerate.sum_interactions(lists)\n",
    "            bad_int_sum[i] = int_sum\n",
    "            bad_int_sums[i] = int_sums\n",
    "        decomp_cnt += 1\n",
    "    if i % 2000 == 0:\n",
    "        print(i, decomp_cnt, len(ex_list))\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(28123, 0.8197124898433685), (7224, 0.8181415572762489), (48736, 0.6984506845474243), (2446, 0.6785046607255936), (1479, 0.6623021401464939)]\n",
      "[(4020, 0.9969721467932686), (22182, 0.9896679029334337), (1939, 0.987184027209878), (6910, 0.9856045837514102), (35727, 0.9844401758164167)]\n"
     ]
    }
   ],
   "source": [
    "sorted_good = sorted(good_correct.items(), key=operator.itemgetter(1))[::-1]\n",
    "sorted_bad = sorted(bad_correct.items(), key=operator.itemgetter(1))[::-1]\n",
    "print(sorted_bad[:5])\n",
    "print(sorted_good[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_torch, im_orig, lab_num = dset.get_im_and_label(1469)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.7241\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " Variable containing:\n",
      " 29\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/linux/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/linux/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8768461346626282"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_max, good_pred = F.softmax(model(im_torch)).max(1)\n",
    "print(good_max, good_pred)\n",
    "F.softmax(bad_model(im_torch)).data[0, good_pred.data[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_exs = set([a[0] for a in sorted_good[:6]])\n",
    "bad_exs = set([a[0] for a in sorted_bad[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-457c65bb81b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/out_imagenet_good_out.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'int_sums'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgood_int_sums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int_sum'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgood_int_sum\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/out_imagenet_bad_out.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'int_sums'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbad_int_sums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int_sum'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbad_int_sum\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "with open('data/out_imagenet_good_out.pkl', 'wb') as fout:\n",
    "    pickle.dump({'int_sums': good_int_sums, 'int_sum': good_int_sum}, fout)\n",
    "    \n",
    "with open('data/out_imagenet_bad_out.pkl', 'wb') as fout:\n",
    "    pickle.dump({'int_sums': bad_int_sums, 'int_sum': bad_int_sum}, fout)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/out_imagenet_good_correct.pkl', 'wb') as fout:\n",
    "    pickle.dump(good_correct, fout)\n",
    "    \n",
    "with open('data/out_imagenet_bad_correct.pkl', 'wb') as fout:\n",
    "    pickle.dump(bad_correct, fout)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/out_imagenet_good_correct.pkl', 'rb') as fin:\n",
    "    good_correct = pickle.load(fin)\n",
    "    \n",
    "with open('data/out_imagenet_bad_correct.pkl', 'rb') as fin:\n",
    "    bad_correct = pickle.load(fin)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  3.1475   4.4626  11.6072  ...    2.8309   1.6987   1.2151\n",
       "[torch.cuda.FloatTensor of size 1x1000 (GPU 0)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_model(im_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c37ffffa51be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                                         \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_orig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_abs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                         im_torch=im_torch, batch=batch, model_type=model_type)        \n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mim_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chandan/agglomerative_attention/agglomerate.py\u001b[0m in \u001b[0;36magglomerate\u001b[0;34m(model, pred_ims, percentile_include, method, sweep_dim, layer, im_orig, lab_num, use_abs, num_iters, im_torch, batch, model_type)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mtiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_tiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msweep_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         scores_orig_raw = get_scores(model, method, ims=tiles, im_torch=im_torch, \n\u001b[0;32m--> 156\u001b[0;31m                         pred_ims=pred_ims, layer=layer, model_type=model_type)\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mscores_track\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefine_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_orig_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_downsampled\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# keep track of these scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chandan/agglomerative_attention/agglomerate.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(model, method, ims, im_torch, pred_ims, layer, model_type)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# can use tqdm here, need to use batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_torch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'build_up'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chandan/agglomerative_attention/cd.py\u001b[0m in \u001b[0;36mcd\u001b[0;34m(blob, im_torch, model, model_type)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate_conv_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chandan/agglomerative_attention/cd.py\u001b[0m in \u001b[0;36mpropagate_activation\u001b[0;34m(relevant, irrelevant, activation)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mrel_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mirrel_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mirrelevant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sweep_dim = 14\n",
    "for i in good_exs:\n",
    "    print(i)\n",
    "    for mod in [model, bad_model]:\n",
    "        im = all_data[i]\n",
    "        im_torch, im_orig, lab_num_correct = Variable(im[0].cuda()), np.copy(im[0].numpy()).squeeze().transpose((1, 2, 0)), im[1].numpy()[0]\n",
    "\n",
    "        lab_pred = np.argmax(dset.pred_ims(mod, np.copy(im_orig)))\n",
    "        pred = mod(im_torch)\n",
    "        _, pred = pred[0].max(0)\n",
    "        pred = pred.data[0]\n",
    "        lists = agglomerate.agglomerate(mod, dset.pred_ims, percentile_include, \n",
    "                                        method, sweep_dim, layer, im_orig, \n",
    "                                        pred, use_abs, num_iters=num_iters, \n",
    "                                        im_torch=im_torch, batch=batch, model_type=model_type)        \n",
    "        im_orig.transpose((1, 2, 0))\n",
    "        # visualize\n",
    "        plt.figure(figsize=(12, 11), facecolor='white')\n",
    "\n",
    "        rows = 7       \n",
    "        num_ims = len(lists['scores_list'])\n",
    "\n",
    "        # original plots\n",
    "        ind, labs = viz.visualize_original_preds(im_orig, lab_num_correct, \n",
    "                                                 lists['comp_scores_raw_list'], lists['scores_orig_raw'],\n",
    "                                                 subplot_rows=rows, dset=dset)\n",
    "\n",
    "        # comp plots\n",
    "        viz.visualize_ims_list(lists['scores_list'], \n",
    "                               cmap_new='redwhiteblue',\n",
    "                               title=dset.lab_dict[lab_pred] + ' scores',\n",
    "                               subplot_row=2, subplot_rows=rows, colorbar=True)\n",
    "        viz.visualize_ims_list(lists['comps_list'],\n",
    "                              title='Chosen blobs',\n",
    "                              subplot_row=3, subplot_rows=rows, colorbar=False, im_orig=im_orig, plot_overlay=True)\n",
    "\n",
    "        # dict plots\n",
    "        viz.visualize_dict_list_top(lists['comp_scores_raw_list'], method,\n",
    "                               subplot_row=4, subplot_rows=rows, ind=ind, labs=labs, use_orig_top=True)\n",
    "        viz.visualize_dict_list_top(lists['comp_scores_raw_list'], method,\n",
    "                        subplot_row=6, subplot_rows=rows, ind=ind, \n",
    "                        dset=dset, use_orig_top=False)\n",
    "        plt.show()\n",
    "    #print(ex_ind)\n",
    "    #if ex_ind > 10:\n",
    "        #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_dim = 14\n",
    "for i in bad_exs:\n",
    "    print(i)\n",
    "    for mod in [model, bad_model]:\n",
    "        im = all_data[i]\n",
    "        im_torch, im_orig, lab_num_correct = Variable(im[0].cuda()), np.copy(im[0].numpy()).squeeze().transpose((1, 2, 0)), im[1].numpy()[0]\n",
    "\n",
    "        lab_pred = np.argmax(dset.pred_ims(mod, np.copy(im_orig)))\n",
    "        pred = mod(im_torch)\n",
    "        print(pred)\n",
    "        _, pred = pred[0].max(0)\n",
    "        pred = pred.data[0]\n",
    "        lists = agglomerate.agglomerate(mod, dset.pred_ims, percentile_include, \n",
    "                                        method, sweep_dim, layer, im_orig, \n",
    "                                        pred, use_abs, num_iters=num_iters, \n",
    "                                        im_torch=im_torch, batch=batch, model_type=model_type)        \n",
    "        im_orig.transpose((1, 2, 0))\n",
    "        # visualize\n",
    "        plt.figure(figsize=(12, 11), facecolor='white')\n",
    "\n",
    "        rows = 7       \n",
    "        num_ims = len(lists['scores_list'])\n",
    "\n",
    "        # original plots\n",
    "        ind, labs = viz.visualize_original_preds(im_orig, lab_num_correct, \n",
    "                                                 lists['comp_scores_raw_list'], lists['scores_orig_raw'],\n",
    "                                                 subplot_rows=rows, dset=dset)\n",
    "\n",
    "        # comp plots\n",
    "        viz.visualize_ims_list(lists['scores_list'], \n",
    "                               cmap_new='redwhiteblue',\n",
    "                               title=dset.lab_dict[lab_pred] + ' scores',\n",
    "                               subplot_row=2, subplot_rows=rows, colorbar=True)\n",
    "        viz.visualize_ims_list(lists['comps_list'],\n",
    "                              title='Chosen blobs',\n",
    "                              subplot_row=3, subplot_rows=rows, colorbar=False, im_orig=im_orig, plot_overlay=True)\n",
    "\n",
    "        # dict plots\n",
    "        viz.visualize_dict_list_top(lists['comp_scores_raw_list'], method,\n",
    "                               subplot_row=4, subplot_rows=rows, ind=ind, labs=labs, use_orig_top=True)\n",
    "        viz.visualize_dict_list_top(lists['comp_scores_raw_list'], method,\n",
    "                        subplot_row=6, subplot_rows=rows, ind=ind, \n",
    "                        dset=dset, use_orig_top=False)\n",
    "        plt.show()\n",
    "    #print(ex_ind)\n",
    "    #if ex_ind > 10:\n",
    "        #break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate mturk viz examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/vision/chandan/agglomerative_attention/agglomerate.py:83: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  im_thresh = np.logical_and(scores >= thresh, ~np.isnan(scores))\n"
     ]
    }
   ],
   "source": [
    "sweep_dim = 14\n",
    "rows = 2\n",
    "out_dir = 'vision_results/imagenet'\n",
    "for i, m in enumerate([model, bad_model]):\n",
    "    model_name = ['model=good', 'model=bad'][i]\n",
    "    for ex in good_exs + bad_exs:\n",
    "        ex_fold = 'ex=good' if ex in good_exs else 'ex=bad'\n",
    "        \n",
    "        \n",
    "        # get data[ex]\n",
    "        im = all_data[ex]\n",
    "        im_torch, im_orig, lab_num_correct = Variable(im[0].cuda()), np.copy(im[0].numpy()).squeeze().transpose((1, 2, 0)), im[1].numpy()[0]\n",
    "\n",
    "        lab_pred = np.argmax(dset.pred_ims(m, np.copy(im_orig)))\n",
    "        pred = m(im_torch)\n",
    "        _, pred = pred[0].max(0)\n",
    "        pred = pred.data[0]\n",
    "        lists = agglomerate.agglomerate(m, dset.pred_ims, percentile_include, \n",
    "                                        method, sweep_dim, layer, im_orig, \n",
    "                                        pred, use_abs, num_iters=num_iters, \n",
    "                                        im_torch=im_torch, batch=batch, model_type=model_type)\n",
    "        \n",
    "\n",
    "        # ACD\n",
    "        fig_name = str(ex) + model_name + '_method=acd_' + ex_fold\n",
    "        plt.figure(figsize=(12, 4), facecolor='white')\n",
    "        ind, labs = viz.visualize_original_preds(im_orig, lab_num_correct, \n",
    "                                         lists['comp_scores_raw_list'], lists['scores_orig_raw'],\n",
    "                                         subplot_rows=rows, dset=dset, mturk=True)\n",
    "        viz.visualize_ims_list(np.copy(lists['comps_list']), title='', subplot_row=1, subplot_rows=rows, \n",
    "                               colorbar=False, im_orig=im_orig, plot_overlay=True, \n",
    "                               mturk=True, num_ims=lists['num_before_final'], comp_scores_raw=lists['comp_scores_raw_list'], lab_num_correct=lab_pred) # mturk stuff\n",
    "        plt.savefig(oj(out_dir, fig_name + '.png'), bbox_inches='tight')\n",
    "\n",
    "        # CD\n",
    "        fig_name = str(ex) + model_name + '_method=cd_'+ ex_fold\n",
    "        plt.figure(figsize=(16, 3), facecolor='white')\n",
    "        ind, labs = viz.visualize_original_preds(im_orig, lab_num_correct, \n",
    "                                         lists['comp_scores_raw_list'], lists['scores_orig_raw'],\n",
    "                                         subplot_rows=1, dset=dset, mturk=True)\n",
    "        plt.savefig(oj(out_dir, fig_name + '.png'), bbox_inches='tight')\n",
    "\n",
    "        # integrated gradients\n",
    "        fig_name = str(ex) + model_name + '_method=ig_'+ ex_fold\n",
    "        scores_ig = score_funcs.ig_scores_cnn(model, im_torch, sweep_dim=sweep_dim, num_classes=1000, im_size=224, ind=ind)\n",
    "        plt.figure(figsize=(16, 3), facecolor='white')\n",
    "        ind, labs = viz.visualize_original_preds(im_orig, lab_num_correct, \n",
    "                                             lists['comp_scores_raw_list'], scores_ig,\n",
    "                                             subplot_rows=1, dset=dset, mturk=True)\n",
    "        \n",
    "        plt.savefig(oj(out_dir, fig_name + '.png'), bbox_inches='tight') \n",
    "        \n",
    "        # break_down\n",
    "        fig_name = str(ex) + model_name + '_method=break_down_'+ ex_fold\n",
    "        tiles_break = tiling.gen_tiles(im_orig, fill=0, method='break_down', sweep_dim=sweep_dim)\n",
    "        preds_break = agglomerate.get_scores(model, method='break_down', ims=tiles_break, \n",
    "                                    im_torch=im_torch, pred_ims=dset.pred_ims, layer='softmax')\n",
    "        plt.figure(figsize=(16, 3), facecolor='white')\n",
    "        ind, labs = viz.visualize_original_preds(im_orig, lab_num_correct, \n",
    "                                             lists['comp_scores_raw_list'], preds_break,\n",
    "                                             subplot_rows=1, dset=dset, mturk=True)\n",
    "        plt.savefig(oj(out_dir, fig_name + '.png'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate supp viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-43070e9579f9>, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-43070e9579f9>\"\u001b[0;36m, line \u001b[0;32m45\u001b[0m\n\u001b[0;31m    plt.savefig(oj(out_dir, fig_name + '.png'), bbox_inches='tight').\u001b[0m\n\u001b[0m                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "good_exs = [4195, 22182, 35727, 1939, 4020, 6910]\n",
    "bad_exs = [7224, 28123, 48736]\n",
    "all_data = pickle.load(open(\"imagenet_examples.pkl\", \"rb\"))\n",
    "good_idxs = list(all_data.keys())[0]\n",
    "sweep_dim = 56\n",
    "rows = 4\n",
    "out_dir = 'vision_results/imagenet/supp'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "for i, m in enumerate([model, bad_model]):\n",
    "    model_name = ['model=good', 'model=bad'][i]\n",
    "    for ex in good_exs + bad_exs:\n",
    "        ex_fold = 'ex=good' if ex in good_exs else 'ex=bad'\n",
    "        \n",
    "        \n",
    "        # get data[ex]\n",
    "        im = all_data[ex]\n",
    "        im_torch, im_orig, lab_num_correct = Variable(im[0].cuda()), np.copy(im[0].numpy()).squeeze().transpose((1, 2, 0)), im[1].numpy()[0]\n",
    "\n",
    "        lab_pred = np.argmax(dset.pred_ims(m, np.copy(im_orig)))\n",
    "        pred = m(im_torch)\n",
    "        _, pred = pred[0].max(0)\n",
    "        pred = pred.data[0]\n",
    "        lists = agglomerate.agglomerate(m, dset.pred_ims, percentile_include, \n",
    "                                        method, sweep_dim, layer, im_orig, \n",
    "                                        pred, use_abs, num_iters=num_iters, \n",
    "                                        im_torch=im_torch, batch=batch, model_type=model_type)\n",
    "        \n",
    "\n",
    "        fig_name = str(ex) + model_name + '_method=acd_' + ex_fold\n",
    "        \n",
    "        plt.figure(figsize=(14, 6), facecolor='white', dpi=300)\n",
    "        ind, labs = viz.visualize_original_preds(im_orig, lab_num_correct, \n",
    "                                 lists['comp_scores_raw_list'], lists['scores_orig_raw'],\n",
    "                                 subplot_rows=rows, dset=dset, mturk=True)\n",
    "        viz.visualize_ims_list(lists['scores_list'], \n",
    "                               cmap_new='redwhiteblue',\n",
    "                               title='Refined scores',\n",
    "                               subplot_row=1, subplot_rows=rows, colorbar=True)\n",
    "        viz.visualize_ims_list(lists['comps_list'],\n",
    "                              title='',\n",
    "                              subplot_row=2, subplot_rows=rows, colorbar=False, im_orig=im_orig, plot_overlay=True, num_ims=lists['num_before_final'], comp_scores_raw=lists['comp_scores_raw_list'], lab_num_correct=lab_pred)\n",
    "        viz.visualize_dict_list(lists['comp_scores_raw_list'], method,\n",
    "                               subplot_row=3, subplot_rows=rows)\n",
    "        plt.savefig(oj(out_dir, fig_name + '.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 11000 12000 13000 14000 15000 16000 17000 18000 19000 20000 21000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/linux/anaconda3/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/linux/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/accounts/projects/vision/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/accounts/projects/vision/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/local/linux/anaconda3/lib/python3.5/site-packages/torchvision-0.2.0-py3.5.egg/torchvision/datasets/folder.py\", line 124, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/usr/local/linux/anaconda3/lib/python3.5/site-packages/torchvision-0.2.0-py3.5.egg/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/usr/local/linux/anaconda3/lib/python3.5/site-packages/torchvision-0.2.0-py3.5.egg/torchvision/transforms/transforms.py\", line 61, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/usr/local/linux/anaconda3/lib/python3.5/site-packages/torchvision-0.2.0-py3.5.egg/torchvision/transforms/functional.py\", line 63, in to_tensor\n",
      "    img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-528636c020b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/linux/anaconda3/lib/python3.5/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/linux/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load top_10, bot_10 above\n",
    "all_data = {}\n",
    "print(len(val_loader))\n",
    "for i, im in enumerate(val_loader):\n",
    "    if i % 1000 == 0:\n",
    "        print(i, end=' ')\n",
    "    if i in top_10 or i in bot_10:\n",
    "        all_data[i] = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use top_10\n",
    "# use bot_10\n",
    "if not os.path.exists('out'):\n",
    "    os.makedirs('out')\n",
    "\n",
    "batches = sent_util.get_batches(range(len(dev_iterator) + 1), train_iterator, dev_iterator, dset='dev') # has batch.text, batch.label\n",
    "print(top_10, bot_10)\n",
    "for ex in np.concatenate((top_10, bot_10)):\n",
    "    ex_fold = 'ex=best' if ex in top_10 else 'ex=worst'\n",
    "    batch = batches[ex]\n",
    "\n",
    "    # ACD\n",
    "    fig_name = str(ex) + '_method=acd_' + ex_fold\n",
    "    viz_args = agglomerate_and_save(method, batch, subtract, percentile_include, num_iters, \n",
    "                      sweep_dim, model, dset, absolute, fig_name=fig_name, use_bad=False, mturk=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
