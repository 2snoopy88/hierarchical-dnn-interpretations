{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sys\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import math\n",
    "from os.path import join as oj\n",
    "import operator\n",
    "sys.path.insert(1, oj(sys.path[0], 'sentiment'))\n",
    "\n",
    "from sentiment import sent_util\n",
    "import tiling_text\n",
    "import scores as score_funcs\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets\n",
    "import agglomerate_text\n",
    "import visualize_text\n",
    "\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = 'dev'\n",
    "method = 'cd'\n",
    "\n",
    "# Not sure what these mean, agglomeration parameters\n",
    "subtract = True\n",
    "percentile_include = 90\n",
    "num_iters = 25\n",
    "absolute = True\n",
    "sweep_dim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /scratch/users/vision/chandan/data/saliency/train_subtrees/best_snapshot_devacc_85.77981651376147_devloss_0.4260834753513336__iter_3000_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/vision/.local/lib/python3.5/site-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'model.LSTMSentiment' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.5/site-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.5/site-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.5/site-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded onto gpu...\n"
     ]
    }
   ],
   "source": [
    "# get model, generate bad model\n",
    "# snapshot_dir = '/accounts/grad/jmurdoch/pytorch/agglomerative_attention/sentiment/results/'\n",
    "# snapshot_file = oj(snapshot_dir, 'best_snapshot_devacc_85.77981651376147_devloss_0.4260834753513336__iter_3000_model.pt')\n",
    "snapshot_file = '/scratch/users/vision/chandan/data/saliency/train_subtrees/best_snapshot_devacc_85.77981651376147_devloss_0.4260834753513336__iter_3000_model.pt'\n",
    "model = sent_util.get_model(snapshot_file)\n",
    "model.eval()\n",
    "\n",
    "# get data\n",
    "inputs, answers, train_iterator, dev_iterator = sent_util.get_sst()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find best, worst examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentiment/model.py:30: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  lstm_out, self.hidden = self.lstm(vecs, self.hidden)\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "print(len(dev_iterator))\n",
    "for i, batch in enumerate(dev_iterator):\n",
    "    lab = batch.label.data[0]\n",
    "    pred = model(batch)\n",
    "    preds.append(pred.data[0, lab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top idxs [ 89  66 315 870  76   2  68  88  11  98]\n",
      "bot idxs [783 838  19 813 650 235 520 724 286 522]\n"
     ]
    }
   ],
   "source": [
    "top_idxs = np.argsort(preds)[::-1]\n",
    "preds[top_idxs[0]]\n",
    "top_10 = top_idxs[:10]\n",
    "bot_10 = top_idxs[-10:][::-1]\n",
    "print('top idxs', top_10)\n",
    "print('bot idxs', bot_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bad model\n",
    "np.random.seed(17042018)\n",
    "modify_prop = 0.25\n",
    "bad_model = copy.deepcopy(model)\n",
    "for param in bad_model.parameters():\n",
    "    num_params = np.prod(list(param.data.size()))\n",
    "    num_modify = modify_prop * num_params\n",
    "    to_modify = np.random.choice([True, False], tuple(param.data.size()), \n",
    "                                 p=(modify_prop, 1-modify_prop))\n",
    "    cpu_param = param.data.cpu().numpy()\n",
    "    #permuted_vars = cpu_param[to_modify]\n",
    "    cpu_param[to_modify] = np.random.permutation(cpu_param[to_modify])\n",
    "    param.data = torch.cuda.FloatTensor(cpu_param) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentiment/model.py:30: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  lstm_out, self.hidden = self.lstm(vecs, self.hidden)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev accuracy of bad model: 0.7981651376146789\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy of bad model\n",
    "\n",
    "dev_iterator.init_epoch()\n",
    "model.eval()\n",
    "num_correct, num_total = 0, 0\n",
    "for batch_idx, batch in enumerate(dev_iterator):\n",
    "    pred = bad_model(batch)\n",
    "    _, max_ind = pred[0].max(0)\n",
    "    if max_ind.data[0] == batch.label.data[0]:\n",
    "        num_correct += 1\n",
    "    num_total += 1\n",
    "print(\"Dev accuracy of bad model:\", num_correct / num_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentiment/model.py:30: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  lstm_out, self.hidden = self.lstm(vecs, self.hidden)\n",
      "/usr/local/linux/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n",
      "/usr/local/linux/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  import sys\n",
      "/usr/local/linux/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n",
      "/usr/local/linux/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "good_correct = {}\n",
    "bad_correct = {}\n",
    "for i, batch in enumerate(dev_iterator):\n",
    "    lab_num = batch.label.data[0]\n",
    "    good_max, good_pred = F.softmax(model(batch)).max(1)\n",
    "    good_pred = good_pred.data[0]; good_max = good_max.data[0]\n",
    "    bad_max, bad_pred = F.softmax(bad_model(batch)).max(1)\n",
    "    bad_pred = bad_pred.data[0]; bad_max = bad_max.data[0]\n",
    "    \n",
    "    if (good_pred == lab_num or bad_pred == lab_num) and good_pred != bad_pred and batch.text.size(0) > 6 and batch.text.size(0) < 20:\n",
    "        if good_pred == lab_num:\n",
    "            good_correct[i] = good_max - F.softmax(bad_model(batch)).data[0, good_pred]\n",
    "        else:\n",
    "            bad_correct[i] = bad_max - F.softmax(model(batch)).data[0, bad_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(173, 0.7540188953280449), (274, 0.7136497497558594), (381, 0.7008907198905945), (266, 0.6861542165279388), (378, 0.683125913143158), (168, 0.6483375132083893)]\n",
      "[(231, 0.782391894608736), (374, 0.600233793258667), (432, 0.5715388506650925)]\n"
     ]
    }
   ],
   "source": [
    "sorted_good = sorted(good_correct.items(), key=operator.itemgetter(1))[::-1]\n",
    "sorted_bad = sorted(bad_correct.items(), key=operator.itemgetter(1))[::-1]\n",
    "good_exs = [a[0] for a in sorted_good[:6]]\n",
    "bad_exs = [a[0] for a in sorted_bad[:3]]\n",
    "print(sorted_good[:6])\n",
    "print(sorted_bad[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute interaction scores for good, bad models\n",
    "good_scores = np.zeros(len(dev_iterator))\n",
    "good_joins = np.zeros(len(dev_iterator))\n",
    "bad_scores = np.zeros(len(dev_iterator))\n",
    "bad_joins = np.zeros(len(dev_iterator))\n",
    "\n",
    "dev_iterator.init_epoch()\n",
    "for batch_idx, batch in enumerate(dev_iterator):\n",
    "    lists = visualize_text.agglomerate_and_save(inputs, method, batch, subtract, percentile_include, num_iters, \n",
    "                      sweep_dim, model, dset, absolute, fig_name=str(batch_idx), use_bad=False, show_pics=False)\n",
    "    good_scores[batch_idx], good_joins[batch_idx] = agglomerate_text.interaction_sum(lists)\n",
    "    lists = visualize_text.agglomerate_and_save(inputs, method, batch, subtract, percentile_include, num_iters, \n",
    "                      sweep_dim, bad_model, dset, absolute, fig_name=str(batch_idx), use_bad=False, show_pics=False)\n",
    "    bad_scores[batch_idx], bad_joins[batch_idx] = agglomerate_text.interaction_sum(lists)\n",
    "    if batch_idx % 20 == 0:\n",
    "        print(batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scores\n",
    "np.save('data/text_good_scores.npy', good_scores)\n",
    "np.save('data/text_bad_scores.npy', bad_scores)\n",
    "np.save('data/text_good_joins.npy', good_joins)\n",
    "np.save('data/text_bad_joins.npy', bad_joins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scores\n",
    "good_scores = np.load('data/text_good_scores.npy')\n",
    "bad_scores = np.load('data/text_bad_scores0.1.npy')\n",
    "good_joins = np.load('data/text_good_joins.npy')\n",
    "bad_joins = np.load('data/text_bad_joins0.1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize scores by number of joins\n",
    "\n",
    "good_scores /= good_joins\n",
    "bad_scores /= bad_joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "good_logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose examples\n",
    "batches = sent_util.get_batches(range(len(dev_iterator) + 1), train_iterator, dev_iterator, dset=dset) # has batch.text, batch.label\n",
    "\n",
    "\n",
    "# Highest interactions on good\n",
    "good_exs = set()\n",
    "bad_exs = set()\n",
    "for ind in np.argsort(np.abs(good_scores - bad_scores))[::-1]:\n",
    "    good_logits = model(batches[ind]).data[0]\n",
    "    bad_logits = bad_model(batches[ind]).data[0]\n",
    "    if (abs(good_logits[1] - good_logits[0]) > 0.5 and abs(bad_logits[1] - bad_logits[0]) > 0.5 and \n",
    "        model.predict(batches[ind]) != bad_model.predict(batches[ind]) and batches[ind].text.size(0) > 6 and\n",
    "        batches[ind].text.size(0) < 20):\n",
    "        if model.predict(batches[ind]) == batches[ind].label.data[0]:\n",
    "            if len(good_exs) < 5:\n",
    "                good_exs |= set([ind])\n",
    "        else:\n",
    "            if len(bad_exs) < 5:\n",
    "                bad_exs |= set([ind])\n",
    "        print(good_scores[ind], bad_scores[ind])\n",
    "        if len(good_exs) == 5 and len(bad_exs) == 5:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerate_and_save(method, batch, subtract, percentile_include, num_iters, \n",
    "                         sweep_dim, model, dset, absolute, fig_name=None, use_bad=False, \n",
    "                         wrong_preds=True, mturk=False, no_text=False):\n",
    "    # output folder\n",
    "    out_dir = oj('out')\n",
    "#     folder_name = 'class_diff' if subtract else 'max_class'\n",
    "#     out_dir = oj('out', method)\n",
    "#     if use_bad:\n",
    "#         out_dir = oj(out_dir, 'inaccurate')\n",
    "#     if wrong_preds:\n",
    "#         out_dir = oj(out_dir, 'wrong')\n",
    "#     if not os.path.exists(out_dir):\n",
    "#         os.makedirs(out_dir)\n",
    "\n",
    "    # get batch, text, label\n",
    "    text_orig = [inputs.vocab.itos[int(ind)] for ind in batch.text.data]\n",
    "    label_actual = int(batch.label) # 0 if positive 1 if negative\n",
    "    scores_all = model(batch).data.cpu().numpy()[0]\n",
    "    label_pred = np.argmax(scores_all)\n",
    "    print('ex_num', fig_name, 'scores_all', scores_all, label_pred, label_actual)\n",
    "    \n",
    "    # sweep agglomerative\n",
    "    lists = agglomerate_text.sweep_agglomerative(model, batch, percentile_include, method, sweep_dim, # only works for sweep_dim = 1\n",
    "                        text_orig, label_pred, num_iters=num_iters, subtract=subtract, absolute=absolute)\n",
    "\n",
    "    # visualize\n",
    "    # visualize_text.visualize_scores(lists['scores_list'][0], label_pred, text_orig, \n",
    "    #                             lists['score_orig'], sweep_dim=1, method=method)\n",
    "    # visualize_text.print_scores(lists, text_orig, num_iters)\n",
    "    lists = agglomerate_text.collapse_tree(lists)\n",
    "\n",
    "    \n",
    "    visualize_text.word_heatmap(text_orig, lists, label_pred, label_actual, method, subtract, mturk, no_text)\n",
    "    plt.savefig(oj(out_dir, fig_name + '.png'), bbox_inches='tight')\n",
    "    \n",
    "    viz_args = (text_orig, lists, label_pred, label_actual, method, subtract)\n",
    "    return viz_args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate final viz examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-93c27129780b>, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-93c27129780b>\"\u001b[0;36m, line \u001b[0;32m41\u001b[0m\n\u001b[0;31m    plt.savefig(oj('out', fig_name + '.png'), bbox_inches='tight').\u001b[0m\n\u001b[0m                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "good_exs = [173, 274, 381, 266, 378, 168]\n",
    "bad_exs = [231, 374, 432]\n",
    "if not os.path.exists('out'):\n",
    "    os.makedirs('out')\n",
    "for ex in good_exs + bad_exs:\n",
    "    for i, m in enumerate([model, bad_model]):\n",
    "        model_name = ['model=good', 'model=bad'][i]\n",
    "    \n",
    "        ex_fold = 'ex=good' if ex in good_exs else 'ex=bad'\n",
    "        batches = sent_util.get_batches(range(len(dev_iterator) + 1), train_iterator, dev_iterator, dset=dset) # has batch.text, batch.label\n",
    "        batch = batches[ex]\n",
    "\n",
    "\n",
    "        # ACD\n",
    "        fig_name = str(ex) + model_name + '_method=acd_' + ex_fold\n",
    "        viz_args = agglomerate_and_save(method, batch, subtract, percentile_include, num_iters, \n",
    "                          sweep_dim, m, dset, absolute, fig_name=fig_name, use_bad=False, mturk=True)\n",
    "\n",
    "        # CD\n",
    "        fig_name = str(ex) + model_name + '_method=cd_'+ ex_fold\n",
    "        (text_orig, lists, label_pred, label_actual, method, subtract) = viz_args\n",
    "        lists['comps_list'] = [lists['comps_list'][0]]\n",
    "        visualize_text.word_heatmap(text_orig, lists, label_pred, label_actual, method, subtract, mturk=True)\n",
    "        plt.savefig(oj('out', fig_name + '.png'), bbox_inches='tight')\n",
    "\n",
    "        # integrated gradients\n",
    "        fig_name = str(ex) + model_name + '_method=ig_'+ ex_fold\n",
    "        scores_ig = score_funcs.ig_scores(batch, model, inputs).reshape((1, -1))\n",
    "        visualize_text.word_heatmap(text_orig, lists, label_pred, label_actual, method, subtract, mturk=True, data=scores_ig)\n",
    "        plt.savefig(oj('out', fig_name + '.png'), bbox_inches='tight')\n",
    "        \n",
    "        # break_down\n",
    "        fig_name = str(ex) + model_name + '_method=break_down_'+ ex_fold\n",
    "        text_orig = [inputs.vocab.itos[int(ind)] for ind in batch.text.data]\n",
    "        label_actual = int(batch.label) # 0 if positive 1 if negative\n",
    "        scores_all = model(batch).data.cpu().numpy()[0]\n",
    "        label_pred = np.argmax(scores_all)\n",
    "        lists = agglomerate_text.sweep_agglomerative(m, batch, percentile_include, 'break_down', sweep_dim,\n",
    "                            text_orig, label_pred, num_iters=0, subtract=subtract, absolute=absolute)\n",
    "        visualize_text.word_heatmap(text_orig, lists, label_pred, label_actual, method, subtract, mturk=True)\n",
    "        plt.savefig(oj('out', fig_name + '.png'), bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate supp viz examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use top_10\n",
    "# use bot_10\n",
    "if not os.path.exists('out'):\n",
    "    os.makedirs('out')\n",
    "\n",
    "batches = sent_util.get_batches(range(len(dev_iterator) + 1), train_iterator, dev_iterator, dset='dev') # has batch.text, batch.label\n",
    "print(top_10, bot_10)\n",
    "for ex in np.concatenate((top_10, bot_10)):\n",
    "    ex_fold = 'ex=best' if ex in top_10 else 'ex=worst'\n",
    "    batch = batches[ex]\n",
    "\n",
    "    # ACD\n",
    "    fig_name = str(ex) + '_method=acd_' + ex_fold\n",
    "    viz_args = agglomerate_and_save(method, batch, subtract, percentile_include, num_iters, \n",
    "                      sweep_dim, model, dset, absolute, fig_name=fig_name, use_bad=False, mturk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
